{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DeepCAD-RT testing pipeline \n",
    "<img src=\"https://github.com/STAR-811/DeepCAD-RT-old/blob/main/images/logo-new.png?raw=true\" width = \"650\" height = \"180\" align=right />\n",
    "\n",
    "This file will demonstrate the basic pipeline for denoising specified data using pre-trained DeepCAD-RT models. A TIFF file will be downloaded automatically to be the example data. More information about the method and relevant results can be found in the companion paper：\n",
    "\n",
    "**Real-time denoising of fluorescence time-lapse imaging enables high-sensitivity observations of biological dynamics beyond the shot-noise limit. bioRxiv (2022).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from deepcad.test_collection import testing_class\n",
    "from deepcad.movie_display import display\n",
    "from deepcad.utils import get_first_filename, download_demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select the file(s) to be processed (download if not exist)\n",
    "The `download_demo` function will download demo files (example data and a pre-trained model) and return the full paths of them. The data will be saved in `/datasets` and the model will be saved in `/pth`. If you want to use your own data for testing, please create a new folder in `/datasets` and copy your data into it. Then, just change `datasets_path` into the name of your dataset folder. All TIFF files inside `datasets_path` will be tested. If you want to use your own model for testing, please change `denoise_model` into the folder containing your model(s). All models inside `denoise_model` will be tested. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://zenodo.org/record/5808571/files/fish_localbrain_demo.zip?download=1\n",
      "To: E:\\01-LYX\\pipPackage\\DeepCAD_RT_pytorch\\notebooks\\datasets\\fish_localbrain_demo.zip\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2.54G/2.54G [31:44<00:00, 1.33MB/s]\n",
      "Downloading...\n",
      "From: https://zenodo.org/record/5808571/files/fish_localbrain_E_20_Iter_6175.pth?download=1\n",
      "To: E:\\01-LYX\\pipPackage\\DeepCAD_RT_pytorch\\notebooks\\pth\\fish_localbrain_best_model_demo\\best_model.pth\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4.10M/4.10M [00:03<00:00, 1.29MB/s]\n",
      "Downloading...\n",
      "From: https://zenodo.org/record/5808571/files/fish_localbrain_para.yaml?download=1\n",
      "To: E:\\01-LYX\\pipPackage\\DeepCAD_RT_pytorch\\notebooks\\pth\\fish_localbrain_best_model_demo\\best_model.yaml\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 337/337 [00:00<00:00, 338kB/s]\n"
     ]
    }
   ],
   "source": [
    "download_demo_file = True\n",
    "if download_demo_file:\n",
    "    file_name='fish_localbrain' # select the demo file you want to test (e.g. 'ATP_3D', 'fish_localbrain', 'NP_3D', ...)\n",
    "    datasets_path, denoise_model =download_demo(download_filename=file_name)\n",
    "else:\n",
    "    datasets_path = 'datasets/2RPN-1000'       # folder containing all files to be tested\n",
    "    denoise_model = '2RPN_202112101128_ov_0.5' # A folder containing all models to be tested"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set the parameters for testing\n",
    "Default setting shows the parameters suitable for the demo file. You can change these parameters according to your data and device. To visualize the testing process, you can set the flags `visualize_images_per_epoch` and `save_test_images_per_epoch` according to your demands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_datasize = 300                   # the number of frames to be tested\n",
    "GPU = '0'                             # the index of GPU you will use for computation (e.g. '0', '0,1', '0,1,2')\n",
    "patch_xy = 150                        # the width and height of 3D patches\n",
    "patch_t = 150                         # the time dimension (frames) of 3D patches\n",
    "overlap_factor = 0.6                  # the overlap factor between two adjacent patches\n",
                                           "# Since the receptive field of 3D-Unet is ~90, seamless stitching requires an overlap (patch_xyt*overlap_factor）of at least 90 pixels.\n",
    "num_workers = 0                       # if you use Windows system, set this to 0.\n",
    "\n",
    "# Setup some parameters for result visualization during the test (optional)\n",
    "visualize_images_per_epoch = False    # whether to display inference performance after each epoch\n",
    "save_test_images_per_epoch = True     # whether to save inference image after each epoch in pth path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Show the input low-SNR data  (optional)\n",
    "Play an input video (optional). This will load the video into memory and it is not an indispensable step. OpenCV library was used for display."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31mDisplaying the first raw file -----> \u001b[0m\n",
      "datasets/fish_localbrain_demo/fish_localbrain.tif\n"
     ]
    }
   ],
   "source": [
    "display_images = True\n",
    "\n",
    "if display_images:\n",
    "    display_filename = get_first_filename(datasets_path)\n",
    "    print('\\033[1;31mDisplaying the first raw file -----> \\033[0m')\n",
    "    print(display_filename)\n",
    "    display_length = 300  # the frames number of the noise movie\n",
    "    # normalize the image and display\n",
    "    display(display_filename, display_length=display_length, norm_min_percent=1, norm_max_percent=98)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a testing object\n",
    "This will creat a testing object by passing all parameters as a dictionary. Parameters not specified in the dictionary will use their default values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31mTesting parameters -----> \u001b[0m\n",
      "{'overlap_factor': 0.4, 'datasets_path': 'datasets/fish_localbrain_demo', 'fmap': 16, 'output_dir': './results', 'pth_dir': './pth', 'batch_size': 1, 'patch_t': 150, 'patch_x': 150, 'patch_y': 150, 'gap_y': 90, 'gap_x': 90, 'gap_t': 90, 'GPU': '0', 'ngpu': 1, 'num_workers': 0, 'scale_factor': 1, 'test_datasize': 300, 'denoise_model': 'fish_localbrain_best_model_demo', 'visualize_images_per_epoch': False, 'save_test_images_per_epoch': True, 'colab_display': False, 'result_display': ''}\n"
     ]
    }
   ],
   "source": [
    "test_dict = {\n",
    "    # dataset dependent parameters\n",
    "    'patch_x': patch_xy,                 # the width of 3D patches\n",
    "    'patch_y': patch_xy,                 # the height of 3D patches\n",
    "    'patch_t': patch_t,                  # the time dimension (frames) of 3D patches\n",
    "    'overlap_factor':overlap_factor,     # overlap factor, \n",
    "    'scale_factor': 1,                   # the factor for image intensity scaling\n",
    "    'test_datasize': test_datasize,      # the number of frames to be tested\n",
    "    'datasets_path': datasets_path,      # folder containing all files to be tested\n",
    "    'pth_dir': './pth',                  # pth file root path\n",
    "    'denoise_model' : denoise_model,     # A folder containing all models to be tested\n",
    "    'output_dir' : './results',          # result file root path\n",
    "    # network related parameters\n",
    "    'fmap': 16,                          # number of feature maps\n",
    "    'GPU': GPU,                          # GPU index\n",
    "    'num_workers': num_workers,          # if you use Windows system, set this to 0.\n",
    "    'visualize_images_per_epoch': visualize_images_per_epoch,  # whether to display inference performance after each epoch\n",
    "    'save_test_images_per_epoch': save_test_images_per_epoch   # whether to save inference image after each epoch in pth path\n",
    "}\n",
    "\n",
    "tc = testing_class(test_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start testing\n",
    "Here we lanuch the testing process. All results will be saved in the `/results` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31mStacks for processing -----> \u001b[0m\n",
      "Total stack number ----->  1\n",
      "fish_localbrain.tif\n",
      "\u001b[1;31mUsing 1 GPU(s) for testing -----> \u001b[0m\n",
      "[Model 1/1, best_model.pth] [Stack 1/1, fish_localbrain.tif] [Patch 75/75] [Time Cost: 11 s] [ETA: 0 s]      \n",
      " Test finished. Save all results to disk.\n"
     ]
    }
   ],
   "source": [
    "tc.run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:deepcadpip2]",
   "language": "python",
   "name": "conda-env-deepcadpip2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
