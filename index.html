---
layout: default
title: Home
---


<div class="page">
  <p> 
<center><img src="https://github.com/STAR-811/Deepcad-RT-page/blob/master/images/logo.PNG?raw=true" width="700" align="middle" /></center>
</p>

  
  <header>
    <h1 class="landing-title">DeepCAD-RT: Real-time denoising of fluorescence time-lapse imaging using deep self-supervised learning </h1>
  </header>
  
 
    <p>
      <center><i class="fa fa-code-fork fa-3x"></i></center>
    </p>

  <p>
  <center><img src="https://github.com/cabooster/DeepCAD-RT/blob/page/images/deepcad1.png?raw=true" width="750" align="middle" /></center>
    Calcium imaging is inherently susceptible to detection noise especially when imaging with high frame rate or under low excitation dosage. However, calcium transients are highly dynamic, non-repetitive activities and a firing pattern cannot be captured twice. Clean images for supervised training of deep neural networks are not accessible. We present DeepCAD, a deep self-supervised learning-based method for calcium imaging denoising. Using our method, detection noise can be effectively removed and the accuracy of neuron extraction and spike inference can be highly improved.
    </p>
  
<a href="https://www.nature.com/articles/s41592-021-01225-0"><img style="float: left; padding: 10px; PADDING-RIGHT: 30px;" alt="paper thumbnail" src="https://github.com/cabooster/DeepCAD-RT/blob/page/images/deepcad3.png?raw=true" width=210></a>
<br><h4>Paper</h4>
<p><a href="https://www.nature.com/articles/s41592-021-01225-0">Nature Methods</a>,  2021. </p>
<h4>Citation</h4>
<p>Li, X., Zhang, G., Wu, J. et al. Reinforcing neuron extraction and spike inference in calcium imaging using deep self-supervised denoising. Nat Methods (2021). https://doi.org/10.1038/s41592-021-01225-0
</p>
<h4>Code: <a href='https://github.com/cabooster/DeepCAD'>PyTorch</a>   </h4>
  <br>
<hr>
  <img src="https://github.com/cabooster/DeepCAD-RT/blob/page/images/deepcad2.png?raw=true" width="460" align="left">
<br><h3>Much faster processing speed and much lower memory cost:</h3>
We constructed a lightweight network and compressed the model parameters by 94%, which consequently reduced 85% processing time and 70% memory consumption. 
<br><h3>Improved pre- and post-processing:</h3>
We augmented the training data by 12-fold to alleviate the data dependency and make the method still tractable with a small amount of data.
<br><h3>Hardware deployment:</h3>
We optimized the hardware deployment of DeepCAD-RT and achieved an overall improvement of a 27-fold reduction in running memory and a 20-fold acceleration in inference speed, which ultimately supports real-time image denoising once incorporated with the microscope acquisition system. 
<br> <h4> <a href='https://github.com/cabooster/DeepCAD-RT'>Paper</a>|<a href='https://github.com/cabooster/DeepCAD-RT'>Code</a>   </h4>
  
   <p>
  <center><img src="https://github.com/cabooster/DeepCAD-RT/blob/page/images/deepcad5.png?raw=true" width="750" align="middle" /></center>
   </p>
  

    <p>
      <br><br><br><center>For more information, you can visit following sub-pages:</center>
    <div nowrap align="center"><a href='https://cabooster.github.io/DeepCAD-RT/About/'>About</a> | <a href='https://cabooster.github.io/DeepCAD-RT/Tutorial/'>Tutorial</a>| <a href='https://cabooster.github.io/DeepCAD-RT/Datasets/'>Datasets</a>| <a href='https://cabooster.github.io/DeepCAD-RT/Gallery/'>Gallery</a></div>
    </p>


  
   

</div>


