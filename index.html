---
layout: default
title: Home
---


<div class="page">
  <p> 
<center><img src="https://github.com/STAR-811/Deepcad-RT-page/blob/master/images/logo.PNG?raw=true" width="700" align="middle" /></center>
</p>

  
  <header>
    <h1 class="landing-title">DeepCAD-RT: Real-time denoising of fluorescence time-lapse imaging using deep self-supervised learning </h1>
  </header>
  
  <div class="text-center">
    <p>
      <i class="fa fa-code-fork fa-3x"></i>
    </p>
    <p> 
    DeepCAD is based on the insight that a deep learning network for image denoising can achieve satisfactory convergence even the target image used for training is another corrupted sampling of the same scene <a href='https://arxiv.org/abs/1803.04189'>[paper link]</a>. We explored the temporal redundancy of calcium imaging and found that any two consecutive frames can be regarded as two independent samplings of the same underlying firing pattern. A single low-SNR stack is sufficient to be a complete training set for DeepCAD. 
 </p>
  <p>
  <center><img src="https://github.com/STAR-811/Deepcad-RT-page/blob/master/images/schematic.png?raw=true" width="600" align="middle" /></center>
    </p>
    <h2>Performance</h2>
<p><br><b>Universal denoising for calcium imaging in zebrafish</b></p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/GN0IO7bGoGg" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe> 
<p><br><b> Denoising performance of DeepCAD-RT of neutrophils in the mouse brain in vivo</b></p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/eyLPVRcEGHs" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
 <p><br><b> Denoising performance of DeepCAD-RT on a recently developed genetically encoded ATP sensor</b></p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/kSMYJgE4M54" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
    <p>
      <br><br><br>For more information, you can visit following sub-pages:
    <div nowrap align="center"><a href='https://cabooster.github.io/DeepCAD-RT/About/'>About</a> | <a href='https://cabooster.github.io/DeepCAD-RT/Tutorial/'>Tutorial</a>| <a href='https://cabooster.github.io/DeepCAD-RT/Datasets/'>Datasets</a>| <a href='https://cabooster.github.io/DeepCAD-RT/Gallery/'>Gallery</a></div>
    </p>
     
  <img src="https://github.com/cabooster/DeepCAD-RT/blob/page/images/deepcad2.png?raw=true" width="300" align="left">
  we present DeepCAD-RT, a versatile self-supervised denoising method for fluorescence time-lapse imaging with real-time processing speed and improved performance. By pruning redundant features inside the network architecture, we constructed a lightweight network and compressed the model parameters by 94%, which consequently reduced 85% processing time and 70% memory consumption. Meanwhile, we augmented the training data by 12-fold to alleviate the data dependency and make the method still tractable with a small amount of data. We show that such a strategy of combining model compression and data augmentation eliminates overfitting and makes the training process stable and easy to harness. Finally, we optimized the hardware deployment of DeepCAD-RT and achieved an overall improvement of a 27-fold reduction in running memory and a 20-fold acceleration in inference speed, which ultimately supports real-time image denoising once incorporated with the microscope acquisition system.
  
<a href="https://arxiv.org/pdf/1703.10593.pdf"><img style="float: left; padding: 10px; PADDING-RIGHT: 30px;" alt="paper thumbnail" src="https://github.com/cabooster/DeepCAD-RT/blob/page/images/gallery_drosophila.png?raw=true" width=300></a>
<br>
we present DeepCAD-RT, a versatile self-supervised denoising method for fluorescence time-lapse imaging with real-time processing speed and improved performance. By pruning redundant features inside the network architecture, we constructed a lightweight network and compressed the model parameters by 94%, which consequently reduced 85% processing time and 70% memory consumption. Meanwhile, we augmented the training data by 12-fold to alleviate the data dependency and make the method still tractable with a small amount of data. We show that such a strategy of combining model compression and data augmentation eliminates overfitting and makes the training process stable and easy to harness. Finally, we optimized the hardware deployment of DeepCAD-RT and achieved an overall improvement of a 27-fold reduction in running memory and a 20-fold acceleration in inference speed, which ultimately supports real-time image denoising once incorporated with the microscope acquisition system.
  
   
  </div>
  
</div>


